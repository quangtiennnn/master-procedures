{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef63ae84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.topic_modeling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtopic_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scripts.topic_modeling'"
     ]
    }
   ],
   "source": [
    "from scripts.topic_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce2de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from stopwordsiso import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "encoder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "stop_word_mul = stopwords(['vi','en'])\n",
    "umap_model=UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model=HDBSCAN(metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model=CountVectorizer(stop_words=list(stop_word_mul), min_df=2, ngram_range=(1,2))\n",
    "keybert_model=KeyBERTInspired()\n",
    "pos_model=PartOfSpeech('en_core_web_sm')\n",
    "mmr_model=MaximalMarginalRelevance(diversity=0.3)\n",
    "representation_model={\n",
    "    'KeyBERT':keybert_model,\n",
    "    'MMR':mmr_model,\n",
    "    'POS':pos_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1065b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(df: pd.DataFrame,corpus_embedding):\n",
    "    return corpus_embedding[df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ,save = 'False',name = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece58468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df: pd.DataFrame,top_n_words=100, **kwargs):\n",
    "    \"\"\"\n",
    "    Topic Modeling with BERTopic process\n",
    "    \"\"\"\n",
    "    docs = df.processed_comment.values\n",
    "    \n",
    "    ### EMBEDDINGS\n",
    "    encoder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "    file_path = 'database/corpus_embeddings.npy'\n",
    "    if os.path.isfile(file_path):\n",
    "        corpus_embeddings = np.load(file_path)\n",
    "        extracted_embedding = extract_embedding(df, corpus_embeddings)\n",
    "    else:\n",
    "        corpus_embeddings = embedding(docs,encoder, type='sample')\n",
    "        df = df.reset_index()\n",
    "        extracted_embedding = extract_embedding(df, corpus_embeddings)\n",
    "    \n",
    "    ### Set default values for parameters\n",
    "    umap_defaults = {\n",
    "        'n_neighbors': 15,\n",
    "        'n_components': 5,\n",
    "        'min_dist': 0.0,\n",
    "        'metric': 'cosine',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    hdbscan_defaults = {\n",
    "        'metric': 'euclidean',\n",
    "        'min_cluster_size': 5,\n",
    "        'min_samples': 1,\n",
    "        'prediction_data': True\n",
    "    }\n",
    "    \n",
    "    ### Override defaults with any provided kwargs\n",
    "    umap_params = {**umap_defaults, **kwargs.get('umap_params', {})}\n",
    "    hdbscan_params = {**hdbscan_defaults, **kwargs.get('hdbscan_params', {})}\n",
    "    \n",
    "    ### DIMENSIONALITY REDUCTION:\n",
    "    umap_model = UMAP(**umap_params)\n",
    "    \n",
    "    ### CLUSTERING:\n",
    "    hdbscan_model = HDBSCAN(**hdbscan_params)\n",
    "\n",
    "    ### VECTORIZERS:\n",
    "    stop_word_mul = stopwords(['vi','en'])\n",
    "    vectorizer_model = CountVectorizer(stop_words=list(stop_word_mul), min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "    ### c-TF-IDF:\n",
    "    ctfidf_model = ClassTfidfTransformer()\n",
    "    \n",
    "    ### REPRESENTATION:\n",
    "    keybert_model = KeyBERTInspired()\n",
    "    pos_model = PartOfSpeech('en_core_web_sm')\n",
    "    mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "    representation_model = {\n",
    "        'KeyBERT': keybert_model,\n",
    "        'MMR': mmr_model,\n",
    "        'POS': pos_model\n",
    "    }\n",
    "    \n",
    "    topic_model = BERTopic(\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        representation_model=representation_model,\n",
    "        # hyperparameters\n",
    "        top_n_words=top_n_words,\n",
    "        verbose=True\n",
    "    )\n",
    "    try:\n",
    "        topics, probs = topic_model.fit_transform(docs, extracted_embedding)\n",
    "        return topics, probs\n",
    "    except Exception as e:\n",
    "        print(e.message, e.args)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c92a352",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m run(\u001b[43msample\u001b[49m,top_n_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "topics, probs = run(sample,top_n_words = 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1d3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
